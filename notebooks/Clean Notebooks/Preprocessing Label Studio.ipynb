{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"mNZSNIQZrFAP","outputId":"70607970-66ae-452f-8ea5-2b715e5f530c"},"outputs":[{"name":"stdout","output_type":"stream","text":["The file has 7369 lines.\n"]}],"source":["def count_lines_in_file(file_path):\n","    with open(file_path, 'r', encoding=\"utf-8\") as file:\n","        lines = file.readlines()\n","        return len(lines)\n","\n","file_path = 'textLine_COVID.txt'\n","line_count = count_lines_in_file(file_path)\n","print(f'The file has {line_count} lines.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rUryaenDrFAY","outputId":"62db2133-0242-45be-805f-1b8148f5d6b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["The file has 6442 lines.\n"]}],"source":["file_path = 'textLine_symptom.txt'\n","line_count = count_lines_in_file(file_path)\n","print(f'The file has {line_count} lines.')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hYLQZbUerFAa"},"outputs":[],"source":["def parse_conll_to_sentences(file_path):\n","    sentences = []\n","    words = []\n","    tags = []\n","\n","    with open(file_path, 'r', encoding=\"utf-8\") as file:\n","        for line in file:\n","            line = line.strip()\n","            if line == '':\n","                if words and tags:\n","                    sentences.append((words, tags))\n","                    words = []\n","                    tags = []\n","            else:\n","                parts = line.split()\n","                if len(parts) == 4:\n","                    word, _, _, tag = parts\n","                    words.append(word)\n","                    tags.append(tag)\n","                else:\n","                    print(f\"Skipping malformed line: {line}\")\n","\n","    if words and tags:\n","        sentences.append((words, tags))\n","\n","    return sentences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4y46V4B7rFAc"},"outputs":[],"source":["import pandas as pd\n","def sentences_to_dataframe(sentences):\n","    data = {\n","        'tokens': [],\n","        'ner_tags': []\n","    }\n","\n","    for words, tags in sentences:\n","        data['tokens'].append(words)\n","        data['ner_tags'].append(tags)\n","\n","    df = pd.DataFrame(data)\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OSN47fJfrFAe","outputId":"df643951-82ff-4f68-bf72-1de54fb8fb99"},"outputs":[{"name":"stdout","output_type":"stream","text":["Skipping malformed line: -DOCSTART- -X- O\n"]}],"source":["file_path = \"test2.conll\"\n","sentences = parse_conll_to_sentences(file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1r14bnHgrFAf"},"outputs":[],"source":["df = sentences_to_dataframe(sentences)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QxHsSdzjrFAf","outputId":"7c62332e-26f0-4878-8be4-1ed655f0be87"},"outputs":[{"data":{"text/plain":["['The',\n"," 'majority',\n"," 'of',\n"," 'people',\n"," 'living',\n"," 'with',\n"," 'Long',\n"," 'Covid',\n"," 'experience',\n"," 'some',\n"," 'form',\n"," 'of',\n"," 'stigma',\n"," 'directly',\n"," 'related',\n"," 'to',\n"," 'their',\n"," 'condition',\n"," ',',\n"," 'according',\n"," 'to',\n"," 'a',\n"," 'new',\n"," 'study',\n"," 'published',\n"," 'in',\n"," 'the',\n"," 'journal',\n"," 'PLOS',\n"," 'ONE',\n"," '.']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.iloc[1][\"tokens\"]"]},{"cell_type":"markdown","metadata":{"id":"IEBlb3fjrFAg"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XTJDj8NKrFAj","outputId":"9bbe7f80-ac19-4e6f-ac8b-32364e55fff1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tokens</th>\n","      <th>ner_tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[Most, people, with, Long, Covid, face, stigma...</td>\n","      <td>[O, O, O, O, O, O, O, O, O]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[The, majority, of, people, living, with, Long...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[An, estimated, 2.3, million, people, are, liv...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[Testimonies, illustrate, profound, stigmas, e...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[In, the, study, ,, conducted, by, researchers...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              tokens  \\\n","0  [Most, people, with, Long, Covid, face, stigma...   \n","1  [The, majority, of, people, living, with, Long...   \n","2  [An, estimated, 2.3, million, people, are, liv...   \n","3  [Testimonies, illustrate, profound, stigmas, e...   \n","4  [In, the, study, ,, conducted, by, researchers...   \n","\n","                                            ner_tags  \n","0                        [O, O, O, O, O, O, O, O, O]  \n","1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n","2  [O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O,...  \n","3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n","4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nnk8BvkjrFAl"},"outputs":[],"source":["import pickle\n","\n","def save_dataframe_to_file(df, file_path):\n","    with open(file_path, 'wb') as file:\n","        pickle.dump(df, file)\n","\n","def load_dataframe_from_file(file_path):\n","    with open(file_path, 'rb') as file:\n","        df = pickle.load(file)\n","    return df\n","\n","pickle_file_path = 'piccolo.pkl'\n","\n","save_dataframe_to_file(df, pickle_file_path)\n","\n","df_loaded = load_dataframe_from_file(pickle_file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oL9iZ8KcrFAn","outputId":"3f3b3d63-38b9-44c4-e511-f2019287a112"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tokens</th>\n","      <th>ner_tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[Most, people, with, Long, Covid, face, stigma...</td>\n","      <td>[O, O, O, O, O, O, O, O, O]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[The, majority, of, people, living, with, Long...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[An, estimated, 2.3, million, people, are, liv...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O,...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[Testimonies, illustrate, profound, stigmas, e...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[In, the, study, ,, conducted, by, researchers...</td>\n","      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              tokens  \\\n","0  [Most, people, with, Long, Covid, face, stigma...   \n","1  [The, majority, of, people, living, with, Long...   \n","2  [An, estimated, 2.3, million, people, are, liv...   \n","3  [Testimonies, illustrate, profound, stigmas, e...   \n","4  [In, the, study, ,, conducted, by, researchers...   \n","\n","                                            ner_tags  \n","0                        [O, O, O, O, O, O, O, O, O]  \n","1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n","2  [O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O,...  \n","3  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n","4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df_loaded.head()"]}],"metadata":{"kernelspec":{"display_name":"ml-env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}
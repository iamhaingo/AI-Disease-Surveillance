{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from doccano_transformer.datasets import NERDataset\n",
    "from doccano_transformer.utils import read_jsonl\n",
    "\n",
    "def convert_to_conll2003(input_file, output_file, tokenizer=str.split, encoding='latin-1'):\n",
    "    \"\"\"\n",
    "    Converts a JSONL file to the CoNLL-2003 format and saves it to an output file.\n",
    "    \"\"\"\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        for entry in read_jsonl(filepath=input_file, dataset=NERDataset, encoding=encoding).to_conll2003(tokenizer=tokenizer):\n",
    "            file.write(entry[\"data\"] + \"\\n\")\n",
    "\n",
    "def parse_conll2003(data):\n",
    "    \"\"\"\n",
    "    Parses CoNLL-2003 formatted data into a list of sentences with token and tag tuples.\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for line in data.splitlines():\n",
    "        if line.startswith(\"-DOCSTART-\") or line == \"\":\n",
    "            if sentence:\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "        else:\n",
    "            parts = line.split()\n",
    "            if len(parts) == 4:\n",
    "                word, _, _, tag = parts\n",
    "                sentence.append((word, tag))\n",
    "    if sentence:\n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "\n",
    "def read_and_parse_conll_file(filename, encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    Reads a CoNLL-2003 formatted file and parses it into structured data.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r', encoding=encoding) as file:\n",
    "        data = file.read()\n",
    "    return parse_conll2003(data)\n",
    "\n",
    "def convert_to_dataframe(sentences):\n",
    "    \"\"\"\n",
    "    Converts parsed sentences into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'tokens': [],\n",
    "        'ner_tags': []\n",
    "    }\n",
    "\n",
    "    for sentence in sentences:\n",
    "        tokens = [word for word, tag in sentence]\n",
    "        ner_tags = [tag for word, tag in sentence]\n",
    "        data['tokens'].append(tokens)\n",
    "        data['ner_tags'].append(ner_tags)\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def main(input_jsonl, output_conll, output_csv, tokenizer=str.split, jsonl_encoding='latin-1', conll_encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    Main function to convert JSONL to CoNLL-2003, parse it, and save as CSV.\n",
    "    \"\"\"\n",
    "    # Convert JSONL to CoNLL-2003\n",
    "    convert_to_conll2003(input_jsonl, output_conll, tokenizer, jsonl_encoding)\n",
    "    \n",
    "    # Parse the CoNLL-2003 file\n",
    "    sentences = read_and_parse_conll_file(output_conll, conll_encoding)\n",
    "    \n",
    "    # Convert parsed data to DataFrame\n",
    "    df = convert_to_dataframe(sentences)\n",
    "    \n",
    "    # Optionally, save the DataFrame to a CSV file\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_jsonl = 'admin.jsonl'\n",
    "    output_conll = 'datasets/test.dataset'\n",
    "    output_csv = 'parsed_data.csv'\n",
    "    \n",
    "    main(input_jsonl, output_conll, output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
